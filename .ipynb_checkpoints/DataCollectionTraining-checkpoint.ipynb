{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e56ba9de",
   "metadata": {},
   "source": [
    "# 1. Import SignLanguageModule notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c9f4988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow==2.5.0 in c:\\users\\dylan\\anaconda3\\envs\\sign_language_to_speech\\lib\\site-packages (2.5.0)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\dylan\\anaconda3\\envs\\sign_language_to_speech\\lib\\site-packages (4.5.3.56)\n",
      "Requirement already satisfied: mediapipe in c:\\users\\dylan\\anaconda3\\envs\\sign_language_to_speech\\lib\\site-packages (0.8.8.1)\n",
      "Requirement already satisfied: sklearn in c:\\users\\dylan\\anaconda3\\envs\\sign_language_to_speech\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\dylan\\anaconda3\\envs\\sign_language_to_speech\\lib\\site-packages (3.4.3)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in c:\\users\\dylan\\anaconda3\\envs\\sign_language_to_speech\\lib\\site-packages (from tensorflow==2.5.0) (3.3.0)\n",
      "Requirement already satisfied: tensorboard~=2.5 in c:\\users\\dylan\\anaconda3\\envs\\sign_language_to_speech\\lib\\site-packages (from tensorflow==2.5.0) (2.7.0)\n",
      "Requirement already satisfied: gast==0.4.0 in c:\\users\\dylan\\anaconda3\\envs\\sign_language_to_speech\\lib\\site-packages (from tensorflow==2.5.0) (0.4.0)\n",
      "Requirement already satisfied: keras-nightly~=2.5.0.dev in c:\\users\\dylan\\anaconda3\\envs\\sign_language_to_speech\\lib\\site-packages (from tensorflow==2.5.0) (2.5.0.dev2021032900)\n",
      "Requirement already satisfied: absl-py~=0.10 in c:\\users\\dylan\\anaconda3\\envs\\sign_language_to_speech\\lib\\site-packages (from tensorflow==2.5.0) (0.15.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.6.0,>=2.5.0rc0 in c:\\users\\dylan\\anaconda3\\envs\\sign_language_to_speech\\lib\\site-packages (from tensorflow==2.5.0) (2.5.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\users\\dylan\\anaconda3\\envs\\sign_language_to_speech\\lib\\site-packages (from tensorflow==2.5.0) (3.18.1)\n",
      "Requirement already satisfied: google-pasta~=0.2 in c:\\users\\dylan\\anaconda3\\envs\\sign_language_to_speech\\lib\\site-packages (from tensorflow==2.5.0) (0.2.0)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in c:\\users\\dylan\\anaconda3\\envs\\sign_language_to_speech\\lib\\site-packages (from tensorflow==2.5.0) (1.12)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in c:\\users\\dylan\\anaconda3\\envs\\sign_language_to_speech\\lib\\site-packages (from tensorflow==2.5.0) (1.1.0)\n",
      "Requirement already satisfied: numpy~=1.19.2 in c:\\users\\dylan\\anaconda3\\envs\\sign_language_to_speech\\lib\\site-packages (from tensorflow==2.5.0) (1.19.5)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in c:\\users\\dylan\\anaconda3\\envs\\sign_language_to_speech\\lib\\site-packages (from tensorflow==2.5.0) (3.7.4.3)\n",
      "Requirement already satisfied: h5py~=3.1.0 in c:\\users\\dylan\\anaconda3\\envs\\sign_language_to_speech\\lib\\site-packages (from tensorflow==2.5.0) (3.1.0)\n",
      "Requirement already satisfied: six~=1.15.0 in c:\\users\\dylan\\anaconda3\\envs\\sign_language_to_speech\\lib\\site-packages (from tensorflow==2.5.0) (1.15.0)\n",
      "Requirement already satisfied: wheel~=0.35 in c:\\users\\dylan\\anaconda3\\envs\\sign_language_to_speech\\lib\\site-packages (from tensorflow==2.5.0) (0.37.0)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in c:\\users\\dylan\\anaconda3\\envs\\sign_language_to_speech\\lib\\site-packages (from tensorflow==2.5.0) (1.12.1)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in c:\\users\\dylan\\anaconda3\\envs\\sign_language_to_speech\\lib\\site-packages (from tensorflow==2.5.0) (1.1.2)\n",
      "Requirement already satisfied: grpcio~=1.34.0 in c:\\users\\dylan\\anaconda3\\envs\\sign_language_to_speech\\lib\\site-packages (from tensorflow==2.5.0) (1.34.1)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in c:\\users\\dylan\\anaconda3\\envs\\sign_language_to_speech\\lib\\site-packages (from tensorflow==2.5.0) (1.6.3)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\dylan\\anaconda3\\envs\\sign_language_to_speech\\lib\\site-packages (from tensorboard~=2.5->tensorflow==2.5.0) (2.0.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\dylan\\anaconda3\\envs\\sign_language_to_speech\\lib\\site-packages (from tensorboard~=2.5->tensorflow==2.5.0) (3.3.4)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\dylan\\anaconda3\\envs\\sign_language_to_speech\\lib\\site-packages (from tensorboard~=2.5->tensorflow==2.5.0) (0.6.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\dylan\\anaconda3\\envs\\sign_language_to_speech\\lib\\site-packages (from tensorboard~=2.5->tensorflow==2.5.0) (2.3.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\dylan\\anaconda3\\envs\\sign_language_to_speech\\lib\\site-packages (from tensorboard~=2.5->tensorflow==2.5.0) (0.4.6)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\dylan\\anaconda3\\envs\\sign_language_to_speech\\lib\\site-packages (from tensorboard~=2.5->tensorflow==2.5.0) (58.0.4)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\dylan\\anaconda3\\envs\\sign_language_to_speech\\lib\\site-packages (from tensorboard~=2.5->tensorflow==2.5.0) (1.8.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\dylan\\anaconda3\\envs\\sign_language_to_speech\\lib\\site-packages (from tensorboard~=2.5->tensorflow==2.5.0) (2.26.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\dylan\\anaconda3\\envs\\sign_language_to_speech\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.0) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\dylan\\anaconda3\\envs\\sign_language_to_speech\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.0) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\dylan\\anaconda3\\envs\\sign_language_to_speech\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.0) (4.2.4)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\dylan\\anaconda3\\envs\\sign_language_to_speech\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow==2.5.0) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\dylan\\anaconda3\\envs\\sign_language_to_speech\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.0) (0.4.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\dylan\\anaconda3\\envs\\sign_language_to_speech\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5.0) (2.0.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\dylan\\anaconda3\\envs\\sign_language_to_speech\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5.0) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dylan\\anaconda3\\envs\\sign_language_to_speech\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5.0) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dylan\\anaconda3\\envs\\sign_language_to_speech\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5.0) (2021.10.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\dylan\\anaconda3\\envs\\sign_language_to_speech\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow==2.5.0) (3.1.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\dylan\\anaconda3\\envs\\sign_language_to_speech\\lib\\site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\dylan\\anaconda3\\envs\\sign_language_to_speech\\lib\\site-packages (from matplotlib) (8.4.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\dylan\\anaconda3\\envs\\sign_language_to_speech\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\dylan\\anaconda3\\envs\\sign_language_to_speech\\lib\\site-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\dylan\\anaconda3\\envs\\sign_language_to_speech\\lib\\site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: attrs>=19.1.0 in c:\\users\\dylan\\anaconda3\\envs\\sign_language_to_speech\\lib\\site-packages (from mediapipe) (21.2.0)\n",
      "Requirement already satisfied: opencv-contrib-python in c:\\users\\dylan\\anaconda3\\envs\\sign_language_to_speech\\lib\\site-packages (from mediapipe) (4.5.3.56)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\dylan\\anaconda3\\envs\\sign_language_to_speech\\lib\\site-packages (from sklearn) (1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\dylan\\anaconda3\\envs\\sign_language_to_speech\\lib\\site-packages (from scikit-learn->sklearn) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\dylan\\anaconda3\\envs\\sign_language_to_speech\\lib\\site-packages (from scikit-learn->sklearn) (3.0.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\users\\dylan\\anaconda3\\envs\\sign_language_to_speech\\lib\\site-packages (from scikit-learn->sklearn) (1.7.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Invalid requirement: '#'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
     ]
    }
   ],
   "source": [
    "import import_ipynb\n",
    "import SignLanguageModule as signLangModule # notebook converted as .py file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b387730",
   "metadata": {},
   "source": [
    "# 2. Collect Keypoint Values for Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00e55152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call function to collect keypoints from SignLanguageModule\n",
    "# signLangModule.collect_keypoints()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd9c72c",
   "metadata": {},
   "source": [
    "# 3. Preprocess Data and Create Labels and Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "800f7432",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb649b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f97351b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create label map for the signs defined in SignLanguageModule\n",
    "# to be used when creating training data in testing data\n",
    "label_map = {label:num for num, label in enumerate(signLangModule.signs)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a71d7d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 0,\n",
       " 'b': 1,\n",
       " 'c': 2,\n",
       " 'd': 3,\n",
       " 'e': 4,\n",
       " 'f': 5,\n",
       " 'g': 6,\n",
       " 'h': 7,\n",
       " 'i': 8,\n",
       " 'j': 9,\n",
       " 'k': 10,\n",
       " 'l': 11,\n",
       " 'm': 12,\n",
       " 'n': 13,\n",
       " 'o': 14,\n",
       " 'p': 15,\n",
       " 'q': 16,\n",
       " 'r': 17,\n",
       " 's': 18,\n",
       " 't': 19,\n",
       " 'u': 20,\n",
       " 'v': 21,\n",
       " 'w': 22,\n",
       " 'x': 23,\n",
       " 'y': 24,\n",
       " 'z': 25,\n",
       " 'hello': 26,\n",
       " 'my': 27,\n",
       " 'name': 28,\n",
       " 'is': 29,\n",
       " 'nice': 30,\n",
       " 'you': 31,\n",
       " 'bye': 32,\n",
       " 'thank you': 33,\n",
       " 'to meet': 34}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a6e38f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequences for feature (x) data\n",
    "# Labels for representing labels (y) data\n",
    "sequences, labels = [], []\n",
    "for sign in signLangModule.signs:\n",
    "    for sequence in np.array(os.listdir(os.path.join(signLangModule.DATA_PATH, sign))).astype(int):\n",
    "        window = []\n",
    "        for frame_num in range(signLangModule.sequence_length):\n",
    "            res = np.load(os.path.join(signLangModule.DATA_PATH, sign, str(sequence), \"{}.npy\".format(frame_num)))\n",
    "            window.append(res)\n",
    "        sequences.append(window)\n",
    "        labels.append(label_map[sign])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03099b63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1050, 30, 1662)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(sequences).shape #check this one for all signs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46d9a993",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1050,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(labels).shape #check this too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c002ca65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store sequences into numpy array to work with\n",
    "X = np.array(sequences)\n",
    "\n",
    "# Convert initial labels, encode them as one-code representation/binary flat\n",
    "y = to_categorical(labels).astype(int)\n",
    "\n",
    "# Specify test data proportion (5% of the data)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "59b610cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(840, 30, 1662)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc90bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "signLangModule.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17fb41f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "signLangModule.signs.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6633dc22",
   "metadata": {},
   "source": [
    "# 4. Train the LSTM Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "435599b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "84/84 [==============================] - 5s 45ms/step - loss: 3.5541 - categorical_accuracy: 0.0345\n",
      "Epoch 2/500\n",
      "84/84 [==============================] - 4s 45ms/step - loss: 3.5539 - categorical_accuracy: 0.0345\n",
      "Epoch 3/500\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 3.5529 - categorical_accuracy: 0.0358"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_25440/2518865102.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Train the built LSTM neural network from SignLanguageModule notebook imported earlier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0msignLangModule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msignLangModule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtb_callback\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#2000 epochs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\sign_language_to_speech\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1181\u001b[0m                 _r=1):\n\u001b[0;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1183\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1184\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\sign_language_to_speech\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    887\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\sign_language_to_speech\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    915\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 917\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\sign_language_to_speech\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3021\u001b[0m       (graph_function,\n\u001b[0;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3023\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3025\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\sign_language_to_speech\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1958\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1959\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1960\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1961\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\sign_language_to_speech\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 591\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\sign_language_to_speech\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train the built LSTM neural network from SignLanguageModule notebook imported earlier\n",
    "signLangModule.model.fit(X_train, y_train, epochs=500, callbacks=[signLangModule.tb_callback]) #2000 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "976d842a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 30, 64)            442112    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 30, 128)           98816     \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 64)                49408     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 35)                1155      \n",
      "=================================================================\n",
      "Total params: 597,731\n",
      "Trainable params: 597,731\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Check model summary\n",
    "signLangModule.model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb8764f",
   "metadata": {},
   "source": [
    "# 5. Save Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c8b0ecc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save weights to be reuse later\n",
    "signLangModule.model.save('sign_language.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02737e4",
   "metadata": {},
   "source": [
    "# 6. Evaluation using Confusion Matrix and Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "106d4bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from sklearn.metrics import multilabel_confusion_matrix, accuracy_score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "deb3c0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = signLangModule.model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f618bf91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert predictions from one-hot encoded representation to categorical label\n",
    "# eg: 0, 1, 2, ... as compared to [1, 0, 0] \n",
    "ytrue = np.argmax(y_test, axis=1).tolist()\n",
    "yhat = np.argmax(yhat, axis=1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d9f276f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[198,   5],\n",
       "        [  4,   3]],\n",
       "\n",
       "       [[207,   0],\n",
       "        [  0,   3]],\n",
       "\n",
       "       [[199,   5],\n",
       "        [  3,   3]],\n",
       "\n",
       "       [[200,   3],\n",
       "        [  6,   1]],\n",
       "\n",
       "       [[201,   2],\n",
       "        [  5,   2]],\n",
       "\n",
       "       [[205,   1],\n",
       "        [  1,   3]],\n",
       "\n",
       "       [[201,   1],\n",
       "        [  4,   4]],\n",
       "\n",
       "       [[206,   2],\n",
       "        [  0,   2]],\n",
       "\n",
       "       [[200,   4],\n",
       "        [  2,   4]],\n",
       "\n",
       "       [[204,   2],\n",
       "        [  0,   4]],\n",
       "\n",
       "       [[204,   1],\n",
       "        [  0,   5]],\n",
       "\n",
       "       [[205,   1],\n",
       "        [  0,   4]],\n",
       "\n",
       "       [[200,   5],\n",
       "        [  2,   3]],\n",
       "\n",
       "       [[201,   2],\n",
       "        [  4,   3]],\n",
       "\n",
       "       [[204,   0],\n",
       "        [  2,   4]],\n",
       "\n",
       "       [[201,   2],\n",
       "        [  5,   2]],\n",
       "\n",
       "       [[199,   2],\n",
       "        [  3,   6]],\n",
       "\n",
       "       [[196,   4],\n",
       "        [  6,   4]],\n",
       "\n",
       "       [[197,   3],\n",
       "        [  7,   3]],\n",
       "\n",
       "       [[198,   4],\n",
       "        [  5,   3]],\n",
       "\n",
       "       [[202,   2],\n",
       "        [  4,   2]],\n",
       "\n",
       "       [[202,   4],\n",
       "        [  3,   1]],\n",
       "\n",
       "       [[197,   7],\n",
       "        [  3,   3]],\n",
       "\n",
       "       [[195,   7],\n",
       "        [  5,   3]],\n",
       "\n",
       "       [[203,   0],\n",
       "        [  2,   5]],\n",
       "\n",
       "       [[201,   3],\n",
       "        [  2,   4]],\n",
       "\n",
       "       [[202,   1],\n",
       "        [  0,   7]],\n",
       "\n",
       "       [[202,   4],\n",
       "        [  0,   4]],\n",
       "\n",
       "       [[205,   0],\n",
       "        [  0,   5]],\n",
       "\n",
       "       [[201,   2],\n",
       "        [  1,   6]],\n",
       "\n",
       "       [[206,   1],\n",
       "        [  0,   3]],\n",
       "\n",
       "       [[203,   0],\n",
       "        [  3,   4]],\n",
       "\n",
       "       [[208,   0],\n",
       "        [  0,   2]],\n",
       "\n",
       "       [[201,   1],\n",
       "        [  0,   8]],\n",
       "\n",
       "       [[204,   1],\n",
       "        [  0,   5]]], dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Returns a confusion matrix sorted by the label order\n",
    "# Matrix organized as \n",
    "# [[True Negative, False Positive],\n",
    "#  [False Negative, True Positive]]\n",
    "multilabel_confusion_matrix(ytrue, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "469b801b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6095238095238096"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check accuracy\n",
    "accuracy_score(ytrue, yhat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
